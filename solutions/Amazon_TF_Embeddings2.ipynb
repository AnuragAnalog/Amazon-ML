{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Amazon TF Embeddings1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNqQrc0iOQA-"
      },
      "source": [
        "# Amazon TF Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hw8azPEtOMlo",
        "outputId": "5ed387a2-9f24-42bc-fe6a-0180799f39b0"
      },
      "source": [
        "# Download the metadata\n",
        "\n",
        "!wget -O \"metadata.zip\" \"https://he-s3.s3.ap-southeast-1.amazonaws.com/media/hackathon/amazon-ml-challenge/product-browse-node-classification-2-7ff04e5a/546b594ee0a211eb.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=8368b4835beb82b55dcfeeae3f4cc8aba7d1e73b16edc75fab683d27aed5e74a&X-Amz-Date=20210730T091738Z&X-Amz-Credential=AKIA6I2ISGOYH7WWS3G5%2F20210730%2Fap-southeast-1%2Fs3%2Faws4_request\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-30 09:18:14--  https://he-s3.s3.ap-southeast-1.amazonaws.com/media/hackathon/amazon-ml-challenge/product-browse-node-classification-2-7ff04e5a/546b594ee0a211eb.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=8368b4835beb82b55dcfeeae3f4cc8aba7d1e73b16edc75fab683d27aed5e74a&X-Amz-Date=20210730T091738Z&X-Amz-Credential=AKIA6I2ISGOYH7WWS3G5%2F20210730%2Fap-southeast-1%2Fs3%2Faws4_request\n",
            "Resolving he-s3.s3.ap-southeast-1.amazonaws.com (he-s3.s3.ap-southeast-1.amazonaws.com)... 52.219.36.47\n",
            "Connecting to he-s3.s3.ap-southeast-1.amazonaws.com (he-s3.s3.ap-southeast-1.amazonaws.com)|52.219.36.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 276 [application/zip]\n",
            "Saving to: ‘metadata.zip’\n",
            "\n",
            "metadata.zip        100%[===================>]     276  --.-KB/s    in 0s      \n",
            "\n",
            "2021-07-30 09:18:14 (12.8 MB/s) - ‘metadata.zip’ saved [276/276]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOPiJZbwOcuR"
      },
      "source": [
        "# Required modules\n",
        "\n",
        "import os\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from zipfile import ZipFile\n",
        "from google.colab import files"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iG6TE_yHO3dm"
      },
      "source": [
        "# Extracting the metadata\n",
        "\n",
        "with ZipFile('metadata.zip', 'r') as zf:\n",
        "    zf.extractall(\"./\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7VYbmlqPExm"
      },
      "source": [
        "# Get dataset link\n",
        "\n",
        "link = open('datasetLink.txt').read()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyXx99HEPVRx",
        "outputId": "3e5869e6-669a-495c-db10-5e9b1189346b"
      },
      "source": [
        "# Download Actual Dataset\n",
        "\n",
        "os.system(f\"wget -O 'dataset.zip' {link}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V87hWwhSP9Ad"
      },
      "source": [
        "# Extracting the dataset\n",
        "\n",
        "with ZipFile('dataset.zip', 'r') as zf:\n",
        "    zf.extractall('./')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CLf-WcoU2YR"
      },
      "source": [
        "# Some paths\n",
        "\n",
        "main_dir = './dataset'\n",
        "train_dir = os.path.join(main_dir, 'train.csv')\n",
        "test_dir = os.path.join(main_dir, 'test.csv')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxhMaHdeVEhb",
        "outputId": "45b6eefc-f9d7-41d7-a097-605d3f6f9057"
      },
      "source": [
        "# Load the train dataset\n",
        "\n",
        "train_embeddings = []\n",
        "\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "\n",
        "train_chunks = pd.read_csv(train_dir, escapechar=\"\\\\\", quoting=csv.QUOTE_NONE, chunksize=10000)\n",
        "for i, df in enumerate(train_chunks):\n",
        "    df = df.replace(np.nan, \"\")\n",
        "    df['text'] = df['BRAND'] + df['TITLE'] + df['DESCRIPTION'] + df['BULLET_POINTS']\n",
        "    del df['BRAND'], df['TITLE'], df['DESCRIPTION'], df['BULLET_POINTS']\n",
        "    train_embed = embed(df['text'].values).numpy()\n",
        "    train_embeddings.append(train_embed)\n",
        "    print(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5281rDYXfnY"
      },
      "source": [
        "# Replacing the nan's with empty string\n",
        "\n",
        "train = train.replace(np.nan, \"\")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PufVc87dXib5"
      },
      "source": [
        "# Merging the text columns\n",
        "# Removing unnessary data\n",
        "\n",
        "train['text'] = train['BRAND'] + train['TITLE'] + train['DESCRIPTION'] + train['BULLET_POINTS']\n",
        "del train['BRAND'], train['TITLE'], train['DESCRIPTION'], train['BULLET_POINTS']"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhKZGDY-Xr9s"
      },
      "source": [
        "# Getting the embeddings\n",
        "\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "train_embed = embed(train['text'].values)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}